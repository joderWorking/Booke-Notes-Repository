{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "157fe534",
   "metadata": {},
   "source": [
    "# Chapter 06: Working with Different Types of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04c2bd1",
   "metadata": {},
   "source": [
    "This chapter covers building expressions, which are the bread and butter of Spark's strutured operations and also review working with variety of different kinds of data, including the following:\n",
    "- Booleans\n",
    "- Numbers\n",
    "- Strings\n",
    "- Dates and timestamps\n",
    "- Handling null\n",
    "- Complex types: arrays, maps, and structs\n",
    "- User-defined types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b86a292",
   "metadata": {},
   "source": [
    "## Import necessary libraries and initialize Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "81c0e5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, instr, pow, round, bround, corr, initcap, lower, upper, ltrim, rtrim, trim, regexp_replace, regexp_extract, rpad, lpad, translate, locate, expr, current_date, current_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "af908ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.16.20.158:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Chapter06</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x11cee7680>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparkSession = SparkSession.builder.master(\"local\").appName(\"Chapter06\").getOrCreate()\n",
    "sparkSession.sparkContext.setLogLevel(\"ERROR\")\n",
    "sparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf1db72",
   "metadata": {},
   "source": [
    "## Read the retail data into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0c968ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: integer (nullable = true)\n",
      " |-- StockCode: integer (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: timestamp (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sparkSession.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\"data/retails.csv\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346deaaf",
   "metadata": {},
   "source": [
    "## Coverting to Spark Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870ecf24",
   "metadata": {},
   "source": [
    "Covert native types to Spark types using the `lit` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a89dd7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+----+\n",
      "|  5|five|5.0|true|\n",
      "+---+----+---+----+\n",
      "|  5|five|5.0|true|\n",
      "|  5|five|5.0|true|\n",
      "|  5|five|5.0|true|\n",
      "|  5|five|5.0|true|\n",
      "|  5|five|5.0|true|\n",
      "|  5|five|5.0|true|\n",
      "|  5|five|5.0|true|\n",
      "|  5|five|5.0|true|\n",
      "|  5|five|5.0|true|\n",
      "|  5|five|5.0|true|\n",
      "|  5|five|5.0|true|\n",
      "|  5|five|5.0|true|\n",
      "|  5|five|5.0|true|\n",
      "|  5|five|5.0|true|\n",
      "|  5|five|5.0|true|\n",
      "|  5|five|5.0|true|\n",
      "|  5|five|5.0|true|\n",
      "|  5|five|5.0|true|\n",
      "|  5|five|5.0|true|\n",
      "|  5|five|5.0|true|\n",
      "+---+----+---+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(lit(5), lit(\"five\"), lit(5.0), lit(True)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d3fa76",
   "metadata": {},
   "source": [
    "## Working with Booleans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5346b0bf",
   "metadata": {},
   "source": [
    "> Questions: Which transactions involve products whose Description contains the word 'BAG' and have revenue greater than 1.5?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1fb715",
   "metadata": {},
   "source": [
    "### Conventional way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7e357ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536376|    20725|LUNCH BAG RED SPOTTY|       6|2010-12-01 09:25:00|     1.65|     14911|   Netherlands|\n",
      "|   536376|    20726|LUNCH BAG BLACK S...|       4|2010-12-01 09:25:00|     1.65|     14911|   Netherlands|\n",
      "|   536388|    23084|  RECYCLING BAG BLUE|       6|2010-12-01 10:12:00|     1.95|     17850|United Kingdom|\n",
      "|   536389|    23085| RECYCLING BAG GREEN|       6|2010-12-01 10:15:00|     1.95|     17850|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(col(\"Description\").contains(\"BAG\") & (col(\"UnitPrice\") * col(\"Quantity\") > 1.5)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b446c46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536376|    20725|LUNCH BAG RED SPOTTY|       6|2010-12-01 09:25:00|     1.65|     14911|   Netherlands|\n",
      "|   536376|    20726|LUNCH BAG BLACK S...|       4|2010-12-01 09:25:00|     1.65|     14911|   Netherlands|\n",
      "|   536388|    23084|  RECYCLING BAG BLUE|       6|2010-12-01 10:12:00|     1.95|     17850|United Kingdom|\n",
      "|   536389|    23085| RECYCLING BAG GREEN|       6|2010-12-01 10:15:00|     1.95|     17850|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col(\"Description\").contains(\"BAG\") & (col(\"UnitPrice\") * col(\"Quantity\") > 1.5)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ea8f0e",
   "metadata": {},
   "source": [
    "### Define filter conditions separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "56fa034a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536376|    20725|LUNCH BAG RED SPOTTY|       6|2010-12-01 09:25:00|     1.65|     14911|   Netherlands|\n",
      "|   536376|    20726|LUNCH BAG BLACK S...|       4|2010-12-01 09:25:00|     1.65|     14911|   Netherlands|\n",
      "|   536388|    23084|  RECYCLING BAG BLUE|       6|2010-12-01 10:12:00|     1.95|     17850|United Kingdom|\n",
      "|   536389|    23085| RECYCLING BAG GREEN|       6|2010-12-01 10:15:00|     1.95|     17850|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "descriptionFilter = col(\"Description\").contains(\"BAG\")\n",
    "revenueFilter = (col(\"UnitPrice\") * col(\"Quantity\")) > 1.5\n",
    "df.where(descriptionFilter & revenueFilter).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2f139e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536376|    20725|LUNCH BAG RED SPOTTY|       6|2010-12-01 09:25:00|     1.65|     14911|   Netherlands|\n",
      "|   536376|    20726|LUNCH BAG BLACK S...|       4|2010-12-01 09:25:00|     1.65|     14911|   Netherlands|\n",
      "|   536388|    23084|  RECYCLING BAG BLUE|       6|2010-12-01 10:12:00|     1.95|     17850|United Kingdom|\n",
      "|   536389|    23085| RECYCLING BAG GREEN|       6|2010-12-01 10:15:00|     1.95|     17850|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "descriptionFilter = instr(col(\"Description\"), \"BAG\") >= 1\n",
    "revenueFilter = (col(\"UnitPrice\") * col(\"Quantity\")) > 1.5\n",
    "df.filter(descriptionFilter & revenueFilter).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c615f39",
   "metadata": {},
   "source": [
    "## Working with Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30390141",
   "metadata": {},
   "source": [
    "Let's imagine that we found out that we mis-recorded the quantity in our retail dataset and the true quantity is equal to `(the \n",
    "current quantity * the unit price)^2 + 5 `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8c00c1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|CustomerId|realQuantity|\n",
      "+----------+------------+\n",
      "|     14911|       294.0|\n",
      "|     14911|      552.56|\n",
      "+----------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "correctQuantity = pow(col(\"Quantity\") * col(\"UnitPrice\"), 2) + 5\n",
    "df.select(\"CustomerId\", correctQuantity.alias(\"realQuantity\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95203f43",
   "metadata": {},
   "source": [
    "Another common numerical task is **rounding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "56d9896f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|Round up|Round down|\n",
      "+--------+----------+\n",
      "|     3.0|       2.0|\n",
      "|     3.0|       2.0|\n",
      "|     3.0|       2.0|\n",
      "|     3.0|       2.0|\n",
      "|     3.0|       2.0|\n",
      "+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(round(lit(2.5)).alias(\"Round up\"), bround(lit(2.5)).alias(\"Round down\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18747a5",
   "metadata": {},
   "source": [
    "Another numerical task is to compute the **correlation** of two columns. We can use it to see if cheaper things are typically bought in greater quantities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d3649cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|corr(Quantity, UnitPrice)|\n",
      "+-------------------------+\n",
      "|      -0.6196211329694905|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(corr(col(\"Quantity\"), col(\"UnitPrice\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b885607",
   "metadata": {},
   "source": [
    "Another common task is to compute statistics for a column or set of columns. We can use `describe` method to achieve exactly this. This will take all numeric columns and calculate the **count**, **mean**, **standard deviation**, **min** and **max**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "063f5502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+--------------------+-----------------+------------------+------------------+--------------+\n",
      "|summary|        InvoiceNo|         StockCode|         Description|         Quantity|         UnitPrice|        CustomerID|       Country|\n",
      "+-------+-----------------+------------------+--------------------+-----------------+------------------+------------------+--------------+\n",
      "|  count|               35|                35|                  35|               35|                35|                35|            35|\n",
      "|   mean|         536385.4|           25814.2|                NULL|6.714285714285714|3.6700000000000013|15056.314285714287|          NULL|\n",
      "| stddev|8.626907291253694|14796.839342158413|                NULL|6.171907077621141| 2.571826999945187|1977.1051739620643|          NULL|\n",
      "|    min|           536373|             20725|BLUE COAT RACK PA...|                1|              0.55|             12583|        France|\n",
      "|    max|           536401|             85032|  WHITE STAR LANTERN|               24|             12.75|             17850|United Kingdom|\n",
      "+-------+-----------------+------------------+--------------------+-----------------+------------------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9378e929",
   "metadata": {},
   "source": [
    "## Working with Strings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b190653",
   "metadata": {},
   "source": [
    "String manipulation is a very common task when working with data. Let's look at some common string operations in Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9016fed",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8b8f5f",
   "metadata": {},
   "source": [
    "`initcap` function will capitalize the first letter of each word in a string column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "66a5d156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|initcap(Description)    |\n",
      "+------------------------+\n",
      "|Jam Making Set With Jars|\n",
      "|Jam Jar With Pink Lid   |\n",
      "|Home Building Block Word|\n",
      "|Regency Cakestand 3 Tier|\n",
      "|Ivory Knitted Scarf     |\n",
      "+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(initcap(col(\"Description\"))).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b19ec06",
   "metadata": {},
   "source": [
    "--- \n",
    "As jut mentioned earlier, `lower` and `upper` functions can be used to change the case of a string column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "21d3767c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+------------------------+------------------------+\n",
      "|Description             |lowered                 |uppered                 |\n",
      "+------------------------+------------------------+------------------------+\n",
      "|JAM MAKING SET WITH JARS|jam making set with jars|JAM MAKING SET WITH JARS|\n",
      "|JAM JAR WITH PINK LID   |jam jar with pink lid   |JAM JAR WITH PINK LID   |\n",
      "|HOME BUILDING BLOCK WORD|home building block word|HOME BUILDING BLOCK WORD|\n",
      "|REGENCY CAKESTAND 3 TIER|regency cakestand 3 tier|REGENCY CAKESTAND 3 TIER|\n",
      "|IVORY KNITTED SCARF     |ivory knitted scarf     |IVORY KNITTED SCARF     |\n",
      "+------------------------+------------------------+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"Description\"), lower(col(\"Description\")).alias(\"lowered\"), upper(col(\"Description\")).alias(\"uppered\")).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eea393",
   "metadata": {},
   "source": [
    "---\n",
    "`ltrim`, `rtrim`, and `trim` functions can be used to remove leading, trailing, or both leading and trailing spaces from a string column.\n",
    "`lpad` and `rpad` functions can be used to pad the left or right side of a string column to a specified length with a specified character. If the string is already longer than the specified length, it will be truncated always from the right side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f51b278c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+-----------+----------+----------+-----------------+-----------------+\n",
      "|ltrimmed      |rtrimmed       |trimmed    |lpadded   |rpadded   |lpadded_truncated|rpadded_truncated|\n",
      "+--------------+---------------+-----------+----------+----------+-----------------+-----------------+\n",
      "|Hello Spark   |    Hello Spark|Hello Spark|*****Hello|Hello*****|HelloWorld       |HelloWorld       |\n",
      "|Hello Spark   |    Hello Spark|Hello Spark|*****Hello|Hello*****|HelloWorld       |HelloWorld       |\n",
      "|Hello Spark   |    Hello Spark|Hello Spark|*****Hello|Hello*****|HelloWorld       |HelloWorld       |\n",
      "|Hello Spark   |    Hello Spark|Hello Spark|*****Hello|Hello*****|HelloWorld       |HelloWorld       |\n",
      "|Hello Spark   |    Hello Spark|Hello Spark|*****Hello|Hello*****|HelloWorld       |HelloWorld       |\n",
      "+--------------+---------------+-----------+----------+----------+-----------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "    ltrim(lit(\"    Hello Spark   \")).alias(\"ltrimmed\"),\n",
    "    rtrim(lit(\"    Hello Spark   \")).alias(\"rtrimmed\"),\n",
    "    trim(lit(\"    Hello Spark   \")).alias(\"trimmed\"),\n",
    "    lpad(lit(\"Hello\"), 10, \"*\").alias(\"lpadded\"),\n",
    "    rpad(lit(\"Hello\"), 10, \"*\").alias(\"rpadded\"),\n",
    "    lpad(lit(\"HelloWorldSpark\"), 10, \"*\").alias(\"lpadded_truncated\"),\n",
    "    rpad(lit(\"HelloWorldSpark\"), 10, \"*\").alias(\"rpadded_truncated\")\n",
    ").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7640f1e7",
   "metadata": {},
   "source": [
    "----\n",
    "### Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489fc94b",
   "metadata": {},
   "source": [
    "- Probaly one of the most frequently performed tasks is searching for the existence of one string in another or replacing all mentions of string with another value. \n",
    "- Spark takes advantage of the complete power of Java regular expressions. The Java regular expression syntax departs from other programming languages. \n",
    "- There are two key functions in Spark that need in order to perform expression taks: `regexp_replace` and `regexp_extract`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "600b2cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+-----------------------------+\n",
      "|replace_colors               |Description                  |\n",
      "+-----------------------------+-----------------------------+\n",
      "|JAM MAKING SET WITH JARS     |JAM MAKING SET WITH JARS     |\n",
      "|JAM JAR WITH PINK LID        |JAM JAR WITH PINK LID        |\n",
      "|HOME BUILDING BLOCK WORD     |HOME BUILDING BLOCK WORD     |\n",
      "|REGENCY CAKESTAND 3 TIER     |REGENCY CAKESTAND 3 TIER     |\n",
      "|IVORY KNITTED SCARF          |IVORY KNITTED SCARF          |\n",
      "|LUNCH BAG COLOR SPOTTY       |LUNCH BAG RED SPOTTY         |\n",
      "|LUNCH BAG COLOR SKULL        |LUNCH BAG BLACK SKULL        |\n",
      "|SILVER ROPE PHOTO FRAME      |SILVER ROPE PHOTO FRAME      |\n",
      "|DOORSTOP RETROSPOT HEART     |DOORSTOP RETROSPOT HEART     |\n",
      "|VINTAGE SNAP CARDS           |VINTAGE SNAP CARDS           |\n",
      "|VINTAGE HEADS & TAILS GAME   |VINTAGE HEADS & TAILS GAME   |\n",
      "|BREAD BIN DINER STYLE        |BREAD BIN DINER STYLE        |\n",
      "|SUGAR STORAGE JAR            |SUGAR STORAGE JAR            |\n",
      "|HEART BISCUIT CUTTERS SET 3  |HEART BISCUIT CUTTERS SET 3  |\n",
      "|COLOR COAT RACK PARIS FASHION|BLUE COAT RACK PARIS FASHION |\n",
      "|RETRO COFFEE MUG COLOR       |RETRO COFFEE MUG BLUE        |\n",
      "|RETRO COFFEE MUG PINK        |RETRO COFFEE MUG PINK        |\n",
      "|DOORSTOP RABBIT              |DOORSTOP RABBIT              |\n",
      "|PACK OF 60 TEATIME CAKE CASES|PACK OF 60 TEATIME CAKE CASES|\n",
      "|COLOR RETROSPOT MINI CASE    |RED RETROSPOT MINI CASE      |\n",
      "+-----------------------------+-----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regex_string = \"BLACK|WHITE|RED|GREEN|BLUE\"\n",
    "\n",
    "df.select(\n",
    "    regexp_replace(col(\"Description\"), regex_string, \"COLOR\").alias(\"replace_colors\"),\n",
    "    col(\"Description\")\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4c9d3ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------------------+\n",
      "|extracted_color|Description                  |\n",
      "+---------------+-----------------------------+\n",
      "|               |JAM MAKING SET WITH JARS     |\n",
      "|               |JAM JAR WITH PINK LID        |\n",
      "|               |HOME BUILDING BLOCK WORD     |\n",
      "|               |REGENCY CAKESTAND 3 TIER     |\n",
      "|               |IVORY KNITTED SCARF          |\n",
      "|RED            |LUNCH BAG RED SPOTTY         |\n",
      "|BLACK          |LUNCH BAG BLACK SKULL        |\n",
      "|               |SILVER ROPE PHOTO FRAME      |\n",
      "|               |DOORSTOP RETROSPOT HEART     |\n",
      "|               |VINTAGE SNAP CARDS           |\n",
      "|               |VINTAGE HEADS & TAILS GAME   |\n",
      "|               |BREAD BIN DINER STYLE        |\n",
      "|               |SUGAR STORAGE JAR            |\n",
      "|               |HEART BISCUIT CUTTERS SET 3  |\n",
      "|BLUE           |BLUE COAT RACK PARIS FASHION |\n",
      "|BLUE           |RETRO COFFEE MUG BLUE        |\n",
      "|               |RETRO COFFEE MUG PINK        |\n",
      "|               |DOORSTOP RABBIT              |\n",
      "|               |PACK OF 60 TEATIME CAKE CASES|\n",
      "|RED            |RED RETROSPOT MINI CASE      |\n",
      "+---------------+-----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\n",
    "    regexp_extract(col(\"Description\"), regex_string, 0).alias(\"extracted_color\"),\n",
    "    col(\"Description\"),\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fd38b4",
   "metadata": {},
   "source": [
    "`translate` function can be used to replace a set of characters in a string with another set of characters. It works on a character-by-character basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "58c8f4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+-----------------------------+\n",
      "|translated                   |Description                  |\n",
      "+-----------------------------+-----------------------------+\n",
      "|JAM MAKING S37 WI7H JARS     |JAM MAKING SET WITH JARS     |\n",
      "|JAM JAR WI7H PINK 1ID        |JAM JAR WITH PINK LID        |\n",
      "|HOM3 BUI1DING B1OCK WORD     |HOME BUILDING BLOCK WORD     |\n",
      "|R3G3NCY CAK3S7AND 3 7I3R     |REGENCY CAKESTAND 3 TIER     |\n",
      "|IVORY KNI773D SCARF          |IVORY KNITTED SCARF          |\n",
      "|1UNCH BAG R3D SPO77Y         |LUNCH BAG RED SPOTTY         |\n",
      "|1UNCH BAG B1ACK SKU11        |LUNCH BAG BLACK SKULL        |\n",
      "|SI1V3R ROP3 PHO7O FRAM3      |SILVER ROPE PHOTO FRAME      |\n",
      "|DOORS7OP R37ROSPO7 H3AR7     |DOORSTOP RETROSPOT HEART     |\n",
      "|VIN7AG3 SNAP CARDS           |VINTAGE SNAP CARDS           |\n",
      "|VIN7AG3 H3ADS & 7AI1S GAM3   |VINTAGE HEADS & TAILS GAME   |\n",
      "|BR3AD BIN DIN3R S7Y13        |BREAD BIN DINER STYLE        |\n",
      "|SUGAR S7ORAG3 JAR            |SUGAR STORAGE JAR            |\n",
      "|H3AR7 BISCUI7 CU773RS S37 3  |HEART BISCUIT CUTTERS SET 3  |\n",
      "|B1U3 COA7 RACK PARIS FASHION |BLUE COAT RACK PARIS FASHION |\n",
      "|R37RO COFF33 MUG B1U3        |RETRO COFFEE MUG BLUE        |\n",
      "|R37RO COFF33 MUG PINK        |RETRO COFFEE MUG PINK        |\n",
      "|DOORS7OP RABBI7              |DOORSTOP RABBIT              |\n",
      "|PACK OF 60 73A7IM3 CAK3 CAS3S|PACK OF 60 TEATIME CAKE CASES|\n",
      "|R3D R37ROSPO7 MINI CAS3      |RED RETROSPOT MINI CASE      |\n",
      "+-----------------------------+-----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(translate(col(\"Description\"), \"LEET\", \"1337\").alias(\"translated\"), col(\"Description\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8da14d8",
   "metadata": {},
   "source": [
    "---\n",
    "Sometimes we simply want to check for the existence rather than extracting or replacing. We can do this with the `contains` method on a column. This will return a boolean column indicating whether the string exists in the given column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "26ac60ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description          |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+---------------------+--------+-------------------+---------+----------+--------------+\n",
      "|536376   |20726    |LUNCH BAG BLACK SKULL|4       |2010-12-01 09:25:00|1.65     |14911     |Netherlands   |\n",
      "|536397   |21734    |WHITE STAR LANTERN   |6       |2010-12-01 10:45:00|3.25     |17850     |United Kingdom|\n",
      "+---------+---------+---------------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "containsBlack = instr(col(\"Description\"), \"BLACK\") >= 1\n",
    "containsWhite = instr(col(\"Description\"), \"WHITE\") >= 1\n",
    "df.where(containsBlack | containsWhite).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "53555a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Column<'CAST(locate(BLACK, Description, 1) AS BOOLEAN) AS is_black'>,\n",
       " Column<'CAST(locate(WHITE, Description, 1) AS BOOLEAN) AS is_white'>,\n",
       " Column<'CAST(locate(RED, Description, 1) AS BOOLEAN) AS is_red'>,\n",
       " Column<'CAST(locate(GREEN, Description, 1) AS BOOLEAN) AS is_green'>,\n",
       " Column<'CAST(locate(BLUE, Description, 1) AS BOOLEAN) AS is_blue'>]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_colors = [\"BLACK\", \"WHITE\", \"RED\", \"GREEN\", \"BLUE\"]\n",
    "def color_locator(column, color_string):\n",
    "    return locate(color_string, column)\\\n",
    "    .cast(\"boolean\")\\\n",
    "    .alias(\"is_\" + color_string.lower())\n",
    "\n",
    "selected_columns = [color_locator(col(\"Description\"), color) for color in simple_colors]\n",
    "\n",
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "899dae5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Column<'CAST(locate(BLACK, Description, 1) AS BOOLEAN) AS is_black'>,\n",
       " Column<'CAST(locate(WHITE, Description, 1) AS BOOLEAN) AS is_white'>,\n",
       " Column<'CAST(locate(RED, Description, 1) AS BOOLEAN) AS is_red'>,\n",
       " Column<'CAST(locate(GREEN, Description, 1) AS BOOLEAN) AS is_green'>,\n",
       " Column<'CAST(locate(BLUE, Description, 1) AS BOOLEAN) AS is_blue'>,\n",
       " Column<'unresolvedstar()'>]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns.append(expr(\"*\"))\n",
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "34c21a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+------+--------+-------+---------+---------+---------------------+--------+-------------------+---------+----------+--------------+\n",
      "|is_black|is_white|is_red|is_green|is_blue|InvoiceNo|StockCode|Description          |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |\n",
      "+--------+--------+------+--------+-------+---------+---------+---------------------+--------+-------------------+---------+----------+--------------+\n",
      "|true    |false   |false |false   |false  |536376   |20726    |LUNCH BAG BLACK SKULL|4       |2010-12-01 09:25:00|1.65     |14911     |Netherlands   |\n",
      "|false   |true    |false |false   |false  |536397   |21734    |WHITE STAR LANTERN   |6       |2010-12-01 10:45:00|3.25     |17850     |United Kingdom|\n",
      "+--------+--------+------+--------+-------+---------+---------+---------------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(*selected_columns).where(expr(\"is_black OR is_white\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42b63d3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57d4d4a",
   "metadata": {},
   "source": [
    "## Working with Dates and Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "23d554c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import date_add, date_sub, date_diff, months_between, to_date, to_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddad9c4",
   "metadata": {},
   "source": [
    "It's always necessary to keep track of time zones and ensure formats are valid. Spark focuses explicitly on two kinds of time-related information: dates and timestamps.\n",
    "\n",
    "**Important Note: Time Zones in Spark**\n",
    "> In version 2.1 and before, Spark parsed according to the machine's timezone if timezones are not explicitly speciffied in the value that you are parsing. \n",
    "> We can set a session local timezone if necessary by setting `spark.conf.sessionLocalTimeZone`, this should be set according to the **Java TimeZone** format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b0ba0992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: integer (nullable = true)\n",
      " |-- StockCode: integer (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: timestamp (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76875c4",
   "metadata": {},
   "source": [
    "- Spark may parse dates/times but you must know their exact format; timestamps only keep seconds, so milliseconds/microseconds are lost, store extra precision as integers (longs) or handle them before converting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "eb2f428d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = false)\n",
      " |-- today: date (nullable = false)\n",
      " |-- now: timestamp (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date_datafame = sparkSession.range(10).withColumn(\"today\", current_date()).withColumn(\"now\", current_timestamp())\n",
    "date_datafame.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76377416",
   "metadata": {},
   "source": [
    "### Add and subtract days from a date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "66f98afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+\n",
      "|today_plus_5|today_minus_5|\n",
      "+------------+-------------+\n",
      "|  2025-12-12|   2025-12-02|\n",
      "|  2025-12-12|   2025-12-02|\n",
      "|  2025-12-12|   2025-12-02|\n",
      "|  2025-12-12|   2025-12-02|\n",
      "|  2025-12-12|   2025-12-02|\n",
      "|  2025-12-12|   2025-12-02|\n",
      "|  2025-12-12|   2025-12-02|\n",
      "|  2025-12-12|   2025-12-02|\n",
      "|  2025-12-12|   2025-12-02|\n",
      "|  2025-12-12|   2025-12-02|\n",
      "+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date_datafame.select(\n",
    "    date_add(col(\"today\"), 5).alias(\"today_plus_5\"),\n",
    "    date_sub(col(\"today\"), 5).alias(\"today_minus_5\"),\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50807de8",
   "metadata": {},
   "source": [
    "### Difference between two dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c02e00c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|days_difference|\n",
      "+---------------+\n",
      "|              7|\n",
      "|              7|\n",
      "|              7|\n",
      "|              7|\n",
      "|              7|\n",
      "|              7|\n",
      "|              7|\n",
      "|              7|\n",
      "|              7|\n",
      "|              7|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date_datafame.withColumn(\"week_ago\", date_sub(col(\"today\"), 7))\\\n",
    "    .select(date_diff(col(\"today\"), col(\"week_ago\")).alias(\"days_difference\"))\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4fbe2866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|months_between|\n",
      "+--------------+\n",
      "|   16.67741935|\n",
      "|   16.67741935|\n",
      "|   16.67741935|\n",
      "|   16.67741935|\n",
      "|   16.67741935|\n",
      "|   16.67741935|\n",
      "|   16.67741935|\n",
      "|   16.67741935|\n",
      "|   16.67741935|\n",
      "|   16.67741935|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date_datafame.select(\n",
    "    months_between(\n",
    "        to_date(lit(\"2017-05-22\")),\n",
    "        to_date(lit(\"2016-01-01\"))\n",
    "    ).alias(\"months_between\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78aa7ec",
   "metadata": {},
   "source": [
    "> Notes: Spark will not throw an error if it cannot parse the date, rather it will return null. This can be tricky in larger pipelines because we might be expecting our data in one format and getting it in another. \n",
    "> \n",
    "> To illustrate, let’s take a look at the date format that has switched from year-month-day to year-day-month. Spark will fail to parse this date and silently return null instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0d337e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|bad_date|\n",
      "+--------+\n",
      "|    NULL|\n",
      "|    NULL|\n",
      "|    NULL|\n",
      "|    NULL|\n",
      "|    NULL|\n",
      "|    NULL|\n",
      "|    NULL|\n",
      "|    NULL|\n",
      "|    NULL|\n",
      "|    NULL|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date_datafame.select(to_date(lit(\"2017-31-12\")).alias(\"bad_date\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bc36f70b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|date      |date2     |\n",
      "+----------+----------+\n",
      "|2017-11-12|2017-12-20|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "date_format = \"yyyy-dd-MM\"\n",
    "cleanDateDF = sparkSession.range(1).select(\n",
    "    to_date(lit(\"2017-12-11\"), date_format).alias(\"date\"),\n",
    "    to_date(lit(\"2017-20-12\"), date_format).alias(\"date2\"),\n",
    ")\n",
    "cleanDateDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e04df51",
   "metadata": {},
   "source": [
    "Let's use an example of `to_timestamp` which accepts a date column and a date format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f8f151e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|timestamp          |\n",
      "+-------------------+\n",
      "|2017-11-12 00:00:00|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleanDateDF.select(to_timestamp(col(\"date\"), date_format).alias(\"timestamp\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895b675b",
   "metadata": {},
   "source": [
    "**Important Notes**: Implicit type casting is an easy way to shoot yourself in the foot, especially when dealing with null values or dates in different time‐zones or formats. We recommend that you parse them explicitly instead of relying on implicit conversions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b96451",
   "metadata": {},
   "source": [
    "## Working with Nulls in Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5de3a9a",
   "metadata": {},
   "source": [
    "As a best practice, we should always use nulls to represent missing or empty data in our Dataframes. Spark can optimize working with null values more than it can if we use empty strings or other values. \n",
    "\n",
    "The primary way of interacting with nulls values, at Dataframe scale, is to use the `.na` subpackage on a Dataframe. \n",
    "\n",
    "There are two things we can do with nulls: drop them or fill them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf41f89",
   "metadata": {},
   "source": [
    "### Coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e689cd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import coalesce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc81bd8",
   "metadata": {},
   "source": [
    "Spark includes a function called `coalesce` that is useful for working with nulls. It accepts a list of columns and returns the first non-null value among them. This is useful when we have multiple columns that might have missing values, and we want to create a new column that takes the first available value from those columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "323b792d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|coalesced                    |\n",
      "+-----------------------------+\n",
      "|JAM MAKING SET WITH JARS     |\n",
      "|JAM JAR WITH PINK LID        |\n",
      "|HOME BUILDING BLOCK WORD     |\n",
      "|REGENCY CAKESTAND 3 TIER     |\n",
      "|IVORY KNITTED SCARF          |\n",
      "|LUNCH BAG RED SPOTTY         |\n",
      "|LUNCH BAG BLACK SKULL        |\n",
      "|SILVER ROPE PHOTO FRAME      |\n",
      "|DOORSTOP RETROSPOT HEART     |\n",
      "|VINTAGE SNAP CARDS           |\n",
      "|VINTAGE HEADS & TAILS GAME   |\n",
      "|BREAD BIN DINER STYLE        |\n",
      "|SUGAR STORAGE JAR            |\n",
      "|HEART BISCUIT CUTTERS SET 3  |\n",
      "|BLUE COAT RACK PARIS FASHION |\n",
      "|RETRO COFFEE MUG BLUE        |\n",
      "|RETRO COFFEE MUG PINK        |\n",
      "|DOORSTOP RABBIT              |\n",
      "|PACK OF 60 TEATIME CAKE CASES|\n",
      "|RED RETROSPOT MINI CASE      |\n",
      "+-----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(coalesce(col(\"Description\"), col(\"CustomerId\")).alias(\"coalesced\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c01037",
   "metadata": {},
   "source": [
    "`drop` function can be used to remove rows with null values from a DataFrame. We can specify how we want to drop the rows using different options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e9dd501b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536373|    22960|JAM MAKING SET WI...|       4|2010-12-01 09:12:00|     4.25|     14911|   Netherlands|\n",
      "|   536373|    22961|JAM JAR WITH PINK...|      12|2010-12-01 09:12:00|     1.95|     14911|   Netherlands|\n",
      "|   536374|    21754|HOME BUILDING BLO...|       3|2010-12-01 09:20:00|     5.95|     13047|United Kingdom|\n",
      "|   536375|    22423|REGENCY CAKESTAND...|       1|2010-12-01 09:24:00|    12.75|     17850|United Kingdom|\n",
      "|   536375|    22301| IVORY KNITTED SCARF|       2|2010-12-01 09:24:00|      7.5|     17850|United Kingdom|\n",
      "|   536376|    20725|LUNCH BAG RED SPOTTY|       6|2010-12-01 09:25:00|     1.65|     14911|   Netherlands|\n",
      "|   536376|    20726|LUNCH BAG BLACK S...|       4|2010-12-01 09:25:00|     1.65|     14911|   Netherlands|\n",
      "|   536377|    84970|SILVER ROPE PHOTO...|       6|2010-12-01 09:28:00|     2.95|     14075|         Spain|\n",
      "|   536378|    22616|DOORSTOP RETROSPO...|       3|2010-12-01 09:30:00|     4.95|     14075|         Spain|\n",
      "|   536379|    21790|  VINTAGE SNAP CARDS|      24|2010-12-01 09:35:00|     0.85|     12583|        France|\n",
      "|   536379|    21791|VINTAGE HEADS & T...|      24|2010-12-01 09:35:00|     0.85|     12583|        France|\n",
      "|   536380|    22867|BREAD BIN DINER S...|       1|2010-12-01 09:40:00|     8.25|     13047|United Kingdom|\n",
      "|   536380|    22868|   SUGAR STORAGE JAR|       3|2010-12-01 09:40:00|     2.75|     13047|United Kingdom|\n",
      "|   536381|    22195|HEART BISCUIT CUT...|       6|2010-12-01 09:44:00|      2.1|     17850|United Kingdom|\n",
      "|   536382|    85032|BLUE COAT RACK PA...|       2|2010-12-01 09:50:00|     7.95|     17850|United Kingdom|\n",
      "|   536383|    21485|RETRO COFFEE MUG ...|      12|2010-12-01 09:55:00|     1.25|     14911|   Netherlands|\n",
      "|   536383|    21486|RETRO COFFEE MUG ...|      12|2010-12-01 09:55:00|     1.25|     14911|   Netherlands|\n",
      "|   536384|    22618|     DOORSTOP RABBIT|       4|2010-12-01 10:00:00|     4.95|     14911|   Netherlands|\n",
      "|   536385|    21975|PACK OF 60 TEATIM...|      24|2010-12-01 10:05:00|     0.55|     12583|        France|\n",
      "|   536386|    22415|RED RETROSPOT MIN...|       2|2010-12-01 10:07:00|     2.95|     14075|         Spain|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dee749ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536373|    22960|JAM MAKING SET WI...|       4|2010-12-01 09:12:00|     4.25|     14911|   Netherlands|\n",
      "|   536373|    22961|JAM JAR WITH PINK...|      12|2010-12-01 09:12:00|     1.95|     14911|   Netherlands|\n",
      "|   536374|    21754|HOME BUILDING BLO...|       3|2010-12-01 09:20:00|     5.95|     13047|United Kingdom|\n",
      "|   536375|    22423|REGENCY CAKESTAND...|       1|2010-12-01 09:24:00|    12.75|     17850|United Kingdom|\n",
      "|   536375|    22301| IVORY KNITTED SCARF|       2|2010-12-01 09:24:00|      7.5|     17850|United Kingdom|\n",
      "|   536376|    20725|LUNCH BAG RED SPOTTY|       6|2010-12-01 09:25:00|     1.65|     14911|   Netherlands|\n",
      "|   536376|    20726|LUNCH BAG BLACK S...|       4|2010-12-01 09:25:00|     1.65|     14911|   Netherlands|\n",
      "|   536377|    84970|SILVER ROPE PHOTO...|       6|2010-12-01 09:28:00|     2.95|     14075|         Spain|\n",
      "|   536378|    22616|DOORSTOP RETROSPO...|       3|2010-12-01 09:30:00|     4.95|     14075|         Spain|\n",
      "|   536379|    21790|  VINTAGE SNAP CARDS|      24|2010-12-01 09:35:00|     0.85|     12583|        France|\n",
      "|   536379|    21791|VINTAGE HEADS & T...|      24|2010-12-01 09:35:00|     0.85|     12583|        France|\n",
      "|   536380|    22867|BREAD BIN DINER S...|       1|2010-12-01 09:40:00|     8.25|     13047|United Kingdom|\n",
      "|   536380|    22868|   SUGAR STORAGE JAR|       3|2010-12-01 09:40:00|     2.75|     13047|United Kingdom|\n",
      "|   536381|    22195|HEART BISCUIT CUT...|       6|2010-12-01 09:44:00|      2.1|     17850|United Kingdom|\n",
      "|   536382|    85032|BLUE COAT RACK PA...|       2|2010-12-01 09:50:00|     7.95|     17850|United Kingdom|\n",
      "|   536383|    21485|RETRO COFFEE MUG ...|      12|2010-12-01 09:55:00|     1.25|     14911|   Netherlands|\n",
      "|   536383|    21486|RETRO COFFEE MUG ...|      12|2010-12-01 09:55:00|     1.25|     14911|   Netherlands|\n",
      "|   536384|    22618|     DOORSTOP RABBIT|       4|2010-12-01 10:00:00|     4.95|     14911|   Netherlands|\n",
      "|   536385|    21975|PACK OF 60 TEATIM...|      24|2010-12-01 10:05:00|     0.55|     12583|        France|\n",
      "|   536386|    22415|RED RETROSPOT MIN...|       2|2010-12-01 10:07:00|     2.95|     14075|         Spain|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(\"any\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b725bc0",
   "metadata": {},
   "source": [
    "Specifying \"any\" will drop rows that have any null values in any column. Using \"all\" will drop rows only if all columns are null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2b9d7c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536373|    22960|JAM MAKING SET WI...|       4|2010-12-01 09:12:00|     4.25|     14911|   Netherlands|\n",
      "|   536373|    22961|JAM JAR WITH PINK...|      12|2010-12-01 09:12:00|     1.95|     14911|   Netherlands|\n",
      "|   536374|    21754|HOME BUILDING BLO...|       3|2010-12-01 09:20:00|     5.95|     13047|United Kingdom|\n",
      "|   536375|    22423|REGENCY CAKESTAND...|       1|2010-12-01 09:24:00|    12.75|     17850|United Kingdom|\n",
      "|   536375|    22301| IVORY KNITTED SCARF|       2|2010-12-01 09:24:00|      7.5|     17850|United Kingdom|\n",
      "|   536376|    20725|LUNCH BAG RED SPOTTY|       6|2010-12-01 09:25:00|     1.65|     14911|   Netherlands|\n",
      "|   536376|    20726|LUNCH BAG BLACK S...|       4|2010-12-01 09:25:00|     1.65|     14911|   Netherlands|\n",
      "|   536377|    84970|SILVER ROPE PHOTO...|       6|2010-12-01 09:28:00|     2.95|     14075|         Spain|\n",
      "|   536378|    22616|DOORSTOP RETROSPO...|       3|2010-12-01 09:30:00|     4.95|     14075|         Spain|\n",
      "|   536379|    21790|  VINTAGE SNAP CARDS|      24|2010-12-01 09:35:00|     0.85|     12583|        France|\n",
      "|   536379|    21791|VINTAGE HEADS & T...|      24|2010-12-01 09:35:00|     0.85|     12583|        France|\n",
      "|   536380|    22867|BREAD BIN DINER S...|       1|2010-12-01 09:40:00|     8.25|     13047|United Kingdom|\n",
      "|   536380|    22868|   SUGAR STORAGE JAR|       3|2010-12-01 09:40:00|     2.75|     13047|United Kingdom|\n",
      "|   536381|    22195|HEART BISCUIT CUT...|       6|2010-12-01 09:44:00|      2.1|     17850|United Kingdom|\n",
      "|   536382|    85032|BLUE COAT RACK PA...|       2|2010-12-01 09:50:00|     7.95|     17850|United Kingdom|\n",
      "|   536383|    21485|RETRO COFFEE MUG ...|      12|2010-12-01 09:55:00|     1.25|     14911|   Netherlands|\n",
      "|   536383|    21486|RETRO COFFEE MUG ...|      12|2010-12-01 09:55:00|     1.25|     14911|   Netherlands|\n",
      "|   536384|    22618|     DOORSTOP RABBIT|       4|2010-12-01 10:00:00|     4.95|     14911|   Netherlands|\n",
      "|   536385|    21975|PACK OF 60 TEATIM...|      24|2010-12-01 10:05:00|     0.55|     12583|        France|\n",
      "|   536386|    22415|RED RETROSPOT MIN...|       2|2010-12-01 10:07:00|     2.95|     14075|         Spain|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(\"all\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bbb33f",
   "metadata": {},
   "source": [
    "`fill` function can be used to replace null values with a specified value. We can provide a single value to replace all nulls or a dictionary to specify different replacement values for different columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c290a08",
   "metadata": {},
   "source": [
    "To fill all null values in columns of type String, we might specify:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2e0715ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536373|    22960|JAM MAKING SET WI...|       4|2010-12-01 09:12:00|     4.25|     14911|   Netherlands|\n",
      "|   536373|    22961|JAM JAR WITH PINK...|      12|2010-12-01 09:12:00|     1.95|     14911|   Netherlands|\n",
      "|   536374|    21754|HOME BUILDING BLO...|       3|2010-12-01 09:20:00|     5.95|     13047|United Kingdom|\n",
      "|   536375|    22423|REGENCY CAKESTAND...|       1|2010-12-01 09:24:00|    12.75|     17850|United Kingdom|\n",
      "|   536375|    22301| IVORY KNITTED SCARF|       2|2010-12-01 09:24:00|      7.5|     17850|United Kingdom|\n",
      "|   536376|    20725|LUNCH BAG RED SPOTTY|       6|2010-12-01 09:25:00|     1.65|     14911|   Netherlands|\n",
      "|   536376|    20726|LUNCH BAG BLACK S...|       4|2010-12-01 09:25:00|     1.65|     14911|   Netherlands|\n",
      "|   536377|    84970|SILVER ROPE PHOTO...|       6|2010-12-01 09:28:00|     2.95|     14075|         Spain|\n",
      "|   536378|    22616|DOORSTOP RETROSPO...|       3|2010-12-01 09:30:00|     4.95|     14075|         Spain|\n",
      "|   536379|    21790|  VINTAGE SNAP CARDS|      24|2010-12-01 09:35:00|     0.85|     12583|        France|\n",
      "|   536379|    21791|VINTAGE HEADS & T...|      24|2010-12-01 09:35:00|     0.85|     12583|        France|\n",
      "|   536380|    22867|BREAD BIN DINER S...|       1|2010-12-01 09:40:00|     8.25|     13047|United Kingdom|\n",
      "|   536380|    22868|   SUGAR STORAGE JAR|       3|2010-12-01 09:40:00|     2.75|     13047|United Kingdom|\n",
      "|   536381|    22195|HEART BISCUIT CUT...|       6|2010-12-01 09:44:00|      2.1|     17850|United Kingdom|\n",
      "|   536382|    85032|BLUE COAT RACK PA...|       2|2010-12-01 09:50:00|     7.95|     17850|United Kingdom|\n",
      "|   536383|    21485|RETRO COFFEE MUG ...|      12|2010-12-01 09:55:00|     1.25|     14911|   Netherlands|\n",
      "|   536383|    21486|RETRO COFFEE MUG ...|      12|2010-12-01 09:55:00|     1.25|     14911|   Netherlands|\n",
      "|   536384|    22618|     DOORSTOP RABBIT|       4|2010-12-01 10:00:00|     4.95|     14911|   Netherlands|\n",
      "|   536385|    21975|PACK OF 60 TEATIM...|      24|2010-12-01 10:05:00|     0.55|     12583|        France|\n",
      "|   536386|    22415|RED RETROSPOT MIN...|       2|2010-12-01 10:07:00|     2.95|     14075|         Spain|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(\"No Value\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f26cbd",
   "metadata": {},
   "source": [
    "We can also provide a dictionary to specify different replacement values for different columns. For example, to fill nulls in the \"Description\" column with \"No Value\" and in the \"CustomerId\" column with -1, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "bb920445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536373|    22960|JAM MAKING SET WI...|       4|2010-12-01 09:12:00|     4.25|     14911|   Netherlands|\n",
      "|   536373|    22961|JAM JAR WITH PINK...|      12|2010-12-01 09:12:00|     1.95|     14911|   Netherlands|\n",
      "|   536374|    21754|HOME BUILDING BLO...|       3|2010-12-01 09:20:00|     5.95|     13047|United Kingdom|\n",
      "|   536375|    22423|REGENCY CAKESTAND...|       1|2010-12-01 09:24:00|    12.75|     17850|United Kingdom|\n",
      "|   536375|    22301| IVORY KNITTED SCARF|       2|2010-12-01 09:24:00|      7.5|     17850|United Kingdom|\n",
      "|   536376|    20725|LUNCH BAG RED SPOTTY|       6|2010-12-01 09:25:00|     1.65|     14911|   Netherlands|\n",
      "|   536376|    20726|LUNCH BAG BLACK S...|       4|2010-12-01 09:25:00|     1.65|     14911|   Netherlands|\n",
      "|   536377|    84970|SILVER ROPE PHOTO...|       6|2010-12-01 09:28:00|     2.95|     14075|         Spain|\n",
      "|   536378|    22616|DOORSTOP RETROSPO...|       3|2010-12-01 09:30:00|     4.95|     14075|         Spain|\n",
      "|   536379|    21790|  VINTAGE SNAP CARDS|      24|2010-12-01 09:35:00|     0.85|     12583|        France|\n",
      "|   536379|    21791|VINTAGE HEADS & T...|      24|2010-12-01 09:35:00|     0.85|     12583|        France|\n",
      "|   536380|    22867|BREAD BIN DINER S...|       1|2010-12-01 09:40:00|     8.25|     13047|United Kingdom|\n",
      "|   536380|    22868|   SUGAR STORAGE JAR|       3|2010-12-01 09:40:00|     2.75|     13047|United Kingdom|\n",
      "|   536381|    22195|HEART BISCUIT CUT...|       6|2010-12-01 09:44:00|      2.1|     17850|United Kingdom|\n",
      "|   536382|    85032|BLUE COAT RACK PA...|       2|2010-12-01 09:50:00|     7.95|     17850|United Kingdom|\n",
      "|   536383|    21485|RETRO COFFEE MUG ...|      12|2010-12-01 09:55:00|     1.25|     14911|   Netherlands|\n",
      "|   536383|    21486|RETRO COFFEE MUG ...|      12|2010-12-01 09:55:00|     1.25|     14911|   Netherlands|\n",
      "|   536384|    22618|     DOORSTOP RABBIT|       4|2010-12-01 10:00:00|     4.95|     14911|   Netherlands|\n",
      "|   536385|    21975|PACK OF 60 TEATIM...|      24|2010-12-01 10:05:00|     0.55|     12583|        France|\n",
      "|   536386|    22415|RED RETROSPOT MIN...|       2|2010-12-01 10:07:00|     2.95|     14075|         Spain|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fill_cols_vals = {\"Description\": \"No Value\", \"CustomerId\": -1}\n",
    "df.na.fill(fill_cols_vals).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19e6ee1",
   "metadata": {},
   "source": [
    "## Working with Complex Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "37f99785",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import struct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8596f1e0",
   "metadata": {},
   "source": [
    "Complex types in Spark include **arrays**, **maps**, and **structs**. These types allow us to work with nested data structures and perform operations on them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515ec6af",
   "metadata": {},
   "source": [
    "### Structs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd95efb0",
   "metadata": {},
   "source": [
    "We can think of structs as a way to group multiple columns into a single column. This is useful when we want to treat a set of related columns as a single entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "86a8046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_df = df.select(struct(col(\"Description\"), col(\"InvoiceNo\")).alias(\"complex\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "440996e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+\n",
      "|complex                                |\n",
      "+---------------------------------------+\n",
      "|{JAM MAKING SET WITH JARS, 536373}     |\n",
      "|{JAM JAR WITH PINK LID, 536373}        |\n",
      "|{HOME BUILDING BLOCK WORD, 536374}     |\n",
      "|{REGENCY CAKESTAND 3 TIER, 536375}     |\n",
      "|{IVORY KNITTED SCARF, 536375}          |\n",
      "|{LUNCH BAG RED SPOTTY, 536376}         |\n",
      "|{LUNCH BAG BLACK SKULL, 536376}        |\n",
      "|{SILVER ROPE PHOTO FRAME, 536377}      |\n",
      "|{DOORSTOP RETROSPOT HEART, 536378}     |\n",
      "|{VINTAGE SNAP CARDS, 536379}           |\n",
      "|{VINTAGE HEADS & TAILS GAME, 536379}   |\n",
      "|{BREAD BIN DINER STYLE, 536380}        |\n",
      "|{SUGAR STORAGE JAR, 536380}            |\n",
      "|{HEART BISCUIT CUTTERS SET 3, 536381}  |\n",
      "|{BLUE COAT RACK PARIS FASHION, 536382} |\n",
      "|{RETRO COFFEE MUG BLUE, 536383}        |\n",
      "|{RETRO COFFEE MUG PINK, 536383}        |\n",
      "|{DOORSTOP RABBIT, 536384}              |\n",
      "|{PACK OF 60 TEATIME CAKE CASES, 536385}|\n",
      "|{RED RETROSPOT MINI CASE, 536386}      |\n",
      "+---------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complex_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2dbf20f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|Description                  |\n",
      "+-----------------------------+\n",
      "|JAM MAKING SET WITH JARS     |\n",
      "|JAM JAR WITH PINK LID        |\n",
      "|HOME BUILDING BLOCK WORD     |\n",
      "|REGENCY CAKESTAND 3 TIER     |\n",
      "|IVORY KNITTED SCARF          |\n",
      "|LUNCH BAG RED SPOTTY         |\n",
      "|LUNCH BAG BLACK SKULL        |\n",
      "|SILVER ROPE PHOTO FRAME      |\n",
      "|DOORSTOP RETROSPOT HEART     |\n",
      "|VINTAGE SNAP CARDS           |\n",
      "|VINTAGE HEADS & TAILS GAME   |\n",
      "|BREAD BIN DINER STYLE        |\n",
      "|SUGAR STORAGE JAR            |\n",
      "|HEART BISCUIT CUTTERS SET 3  |\n",
      "|BLUE COAT RACK PARIS FASHION |\n",
      "|RETRO COFFEE MUG BLUE        |\n",
      "|RETRO COFFEE MUG PINK        |\n",
      "|DOORSTOP RABBIT              |\n",
      "|PACK OF 60 TEATIME CAKE CASES|\n",
      "|RED RETROSPOT MINI CASE      |\n",
      "+-----------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complex_df.select(\"complex.Description\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "da40a482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+---------+\n",
      "|Description                  |InvoiceNo|\n",
      "+-----------------------------+---------+\n",
      "|JAM MAKING SET WITH JARS     |536373   |\n",
      "|JAM JAR WITH PINK LID        |536373   |\n",
      "|HOME BUILDING BLOCK WORD     |536374   |\n",
      "|REGENCY CAKESTAND 3 TIER     |536375   |\n",
      "|IVORY KNITTED SCARF          |536375   |\n",
      "|LUNCH BAG RED SPOTTY         |536376   |\n",
      "|LUNCH BAG BLACK SKULL        |536376   |\n",
      "|SILVER ROPE PHOTO FRAME      |536377   |\n",
      "|DOORSTOP RETROSPOT HEART     |536378   |\n",
      "|VINTAGE SNAP CARDS           |536379   |\n",
      "|VINTAGE HEADS & TAILS GAME   |536379   |\n",
      "|BREAD BIN DINER STYLE        |536380   |\n",
      "|SUGAR STORAGE JAR            |536380   |\n",
      "|HEART BISCUIT CUTTERS SET 3  |536381   |\n",
      "|BLUE COAT RACK PARIS FASHION |536382   |\n",
      "|RETRO COFFEE MUG BLUE        |536383   |\n",
      "|RETRO COFFEE MUG PINK        |536383   |\n",
      "|DOORSTOP RABBIT              |536384   |\n",
      "|PACK OF 60 TEATIME CAKE CASES|536385   |\n",
      "|RED RETROSPOT MINI CASE      |536386   |\n",
      "+-----------------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complex_df.select(\"complex.*\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea56616",
   "metadata": {},
   "source": [
    "### Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7222f9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split, size, array_contains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4bc3c8",
   "metadata": {},
   "source": [
    "To define arrays, let's walk through an example. With our current data, our objectives is to take every single word in our Description column and convert that into a row in our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8a64bd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_splitted_df = df.select(split(col(\"Description\"), \" \" ).alias(\"Description_Split\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b3d66a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|first_word|\n",
      "+----------+\n",
      "|JAM       |\n",
      "|JAM       |\n",
      "|HOME      |\n",
      "|REGENCY   |\n",
      "|IVORY     |\n",
      "|LUNCH     |\n",
      "|LUNCH     |\n",
      "|SILVER    |\n",
      "|DOORSTOP  |\n",
      "|VINTAGE   |\n",
      "|VINTAGE   |\n",
      "|BREAD     |\n",
      "|SUGAR     |\n",
      "|HEART     |\n",
      "|BLUE      |\n",
      "|RETRO     |\n",
      "|RETRO     |\n",
      "|DOORSTOP  |\n",
      "|PACK      |\n",
      "|RED       |\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query the values of the array using Python-like syntax:\n",
    "desc_splitted_df.select(col(\"Description_Split\").getItem(0).alias(\"first_word\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1ffb78",
   "metadata": {},
   "source": [
    "We can determine the array's length using the `size` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4f8b6e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|array_size|\n",
      "+----------+\n",
      "|5         |\n",
      "|5         |\n",
      "|4         |\n",
      "|4         |\n",
      "|3         |\n",
      "|4         |\n",
      "|4         |\n",
      "|4         |\n",
      "|3         |\n",
      "|3         |\n",
      "|5         |\n",
      "|4         |\n",
      "|3         |\n",
      "|5         |\n",
      "|5         |\n",
      "|4         |\n",
      "|4         |\n",
      "|2         |\n",
      "|6         |\n",
      "|4         |\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "desc_splitted_df.select(size(col(\"Description_Split\")).alias(\"array_size\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8b84a7",
   "metadata": {},
   "source": [
    "`array_contains` function can be used to check if an array contains a specific value. It returns a boolean column indicating whether the value exists in the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2a68ff1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|contains_white|\n",
      "+--------------+\n",
      "|true          |\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "desc_splitted_df.select(array_contains(col(\"Description_Split\"), \"WHITE\").alias(\"contains_white\")).filter(col(\"contains_white\") == True).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6f64b7",
   "metadata": {},
   "source": [
    "`explode` function can be used to transform an array column into multiple rows, one for each element in the array. This is useful when we want to flatten an array into individual rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "bd89f577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "23fbeb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+---------+---------+\n",
      "|Description             |InvoiceNo|exploded |\n",
      "+------------------------+---------+---------+\n",
      "|JAM MAKING SET WITH JARS|536373   |JAM      |\n",
      "|JAM MAKING SET WITH JARS|536373   |MAKING   |\n",
      "|JAM MAKING SET WITH JARS|536373   |SET      |\n",
      "|JAM MAKING SET WITH JARS|536373   |WITH     |\n",
      "|JAM MAKING SET WITH JARS|536373   |JARS     |\n",
      "|JAM JAR WITH PINK LID   |536373   |JAM      |\n",
      "|JAM JAR WITH PINK LID   |536373   |JAR      |\n",
      "|JAM JAR WITH PINK LID   |536373   |WITH     |\n",
      "|JAM JAR WITH PINK LID   |536373   |PINK     |\n",
      "|JAM JAR WITH PINK LID   |536373   |LID      |\n",
      "|HOME BUILDING BLOCK WORD|536374   |HOME     |\n",
      "|HOME BUILDING BLOCK WORD|536374   |BUILDING |\n",
      "|HOME BUILDING BLOCK WORD|536374   |BLOCK    |\n",
      "|HOME BUILDING BLOCK WORD|536374   |WORD     |\n",
      "|REGENCY CAKESTAND 3 TIER|536375   |REGENCY  |\n",
      "|REGENCY CAKESTAND 3 TIER|536375   |CAKESTAND|\n",
      "|REGENCY CAKESTAND 3 TIER|536375   |3        |\n",
      "|REGENCY CAKESTAND 3 TIER|536375   |TIER     |\n",
      "|IVORY KNITTED SCARF     |536375   |IVORY    |\n",
      "|IVORY KNITTED SCARF     |536375   |KNITTED  |\n",
      "+------------------------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"splitted\", split(col(\"Description\"), \" \"))\\\n",
    "    .withColumn(\"exploded\", explode(col(\"splitted\")))\\\n",
    "    .select(\"Description\", \"InvoiceNo\", \"exploded\")\\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4825c9be",
   "metadata": {},
   "source": [
    "### Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "69023d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import create_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecde64d3",
   "metadata": {},
   "source": [
    "Maps are another complex type in Spark that allow us to store key-value pairs. This is useful when we want to represent data that has a dynamic set of attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fd7d97cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+\n",
      "|description_invoice_map                  |\n",
      "+-----------------------------------------+\n",
      "|{JAM MAKING SET WITH JARS -> 536373}     |\n",
      "|{JAM JAR WITH PINK LID -> 536373}        |\n",
      "|{HOME BUILDING BLOCK WORD -> 536374}     |\n",
      "|{REGENCY CAKESTAND 3 TIER -> 536375}     |\n",
      "|{IVORY KNITTED SCARF -> 536375}          |\n",
      "|{LUNCH BAG RED SPOTTY -> 536376}         |\n",
      "|{LUNCH BAG BLACK SKULL -> 536376}        |\n",
      "|{SILVER ROPE PHOTO FRAME -> 536377}      |\n",
      "|{DOORSTOP RETROSPOT HEART -> 536378}     |\n",
      "|{VINTAGE SNAP CARDS -> 536379}           |\n",
      "|{VINTAGE HEADS & TAILS GAME -> 536379}   |\n",
      "|{BREAD BIN DINER STYLE -> 536380}        |\n",
      "|{SUGAR STORAGE JAR -> 536380}            |\n",
      "|{HEART BISCUIT CUTTERS SET 3 -> 536381}  |\n",
      "|{BLUE COAT RACK PARIS FASHION -> 536382} |\n",
      "|{RETRO COFFEE MUG BLUE -> 536383}        |\n",
      "|{RETRO COFFEE MUG PINK -> 536383}        |\n",
      "|{DOORSTOP RABBIT -> 536384}              |\n",
      "|{PACK OF 60 TEATIME CAKE CASES -> 536385}|\n",
      "|{RED RETROSPOT MINI CASE -> 536386}      |\n",
      "+-----------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(create_map(col(\"Description\"), col(\"InvoiceNo\")).alias(\"description_invoice_map\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0a7e3f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|invoice_no|\n",
      "+----------+\n",
      "|    536373|\n",
      "|      NULL|\n",
      "+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(create_map(col(\"Description\"), col(\"InvoiceNo\")).alias(\"description_invoice_map\"))\\\n",
    "    .selectExpr(\"description_invoice_map['JAM MAKING SET WITH JARS'] as invoice_no\")\\\n",
    "    .show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4dbe3a",
   "metadata": {},
   "source": [
    "We can also `explode` **map types**, which will turn them into **columns**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6b433043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+----------+\n",
      "|description                  |invoice_no|\n",
      "+-----------------------------+----------+\n",
      "|JAM MAKING SET WITH JARS     |536373    |\n",
      "|JAM JAR WITH PINK LID        |536373    |\n",
      "|HOME BUILDING BLOCK WORD     |536374    |\n",
      "|REGENCY CAKESTAND 3 TIER     |536375    |\n",
      "|IVORY KNITTED SCARF          |536375    |\n",
      "|LUNCH BAG RED SPOTTY         |536376    |\n",
      "|LUNCH BAG BLACK SKULL        |536376    |\n",
      "|SILVER ROPE PHOTO FRAME      |536377    |\n",
      "|DOORSTOP RETROSPOT HEART     |536378    |\n",
      "|VINTAGE SNAP CARDS           |536379    |\n",
      "|VINTAGE HEADS & TAILS GAME   |536379    |\n",
      "|BREAD BIN DINER STYLE        |536380    |\n",
      "|SUGAR STORAGE JAR            |536380    |\n",
      "|HEART BISCUIT CUTTERS SET 3  |536381    |\n",
      "|BLUE COAT RACK PARIS FASHION |536382    |\n",
      "|RETRO COFFEE MUG BLUE        |536383    |\n",
      "|RETRO COFFEE MUG PINK        |536383    |\n",
      "|DOORSTOP RABBIT              |536384    |\n",
      "|PACK OF 60 TEATIME CAKE CASES|536385    |\n",
      "|RED RETROSPOT MINI CASE      |536386    |\n",
      "+-----------------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(create_map(col(\"Description\"), col(\"InvoiceNo\")).alias(\"description_invoice_map\")).selectExpr(\"explode(description_invoice_map) as (description, invoice_no)\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd7119c",
   "metadata": {},
   "source": [
    "## Working with JSON"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
